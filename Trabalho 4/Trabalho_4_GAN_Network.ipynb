{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabalho_4-GAN_Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD1rDsnVxUBM"
      },
      "source": [
        "# Generative Adversarial Network (GAN)\n",
        "\n",
        "Generative Adversarial Networks, ou GANs, são redes neurais utilizadas para implementação de modelos generativos, isto é, modelos que geram dados seguindo o padrão dos dados de entrada. \n",
        "\n",
        "Essas redes são compostas por dois sub-modelos principais: o modelo gerador e o modelo discriminante.\n",
        "\n",
        "O modelo gerador constitui a primeira parte das GANs e é utilizado, como sugere o nome, para a geração de novos exemplos baseados nos dados de entrada. Já a segunda parte, o modelo discriminante, é responsável pela discrmininação entre dados reais e falsos (gerados pela rede)\n",
        "\n",
        "\"*Generative adversarial networks are based on a game theoretic scenario in which the generator network must compete against an adversary. The generator network directly produces samples. Its adversary, the discriminator network, attempts to distinguish between samples drawn from the training data and samples drawn from the generator*.\" - <a href=\"https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618/ref=as_li_ss_tl?keywords=deep+learning&qid=1553730173&s=books&sr=1-1&linkCode=sl1&tag=inspiredalgor-20&linkId=e9ef92a6248b927689728a8bf72b7cd1&language=en_US\" target=\"_blank\">Deep Learning</a>, 2016, página 699.\n",
        "\n",
        "Neste notebobok, iremos utilizalá-las para a predição de frame de uma cena do filme O Hobbit: Uma Jornada Inesperada (Peter Jackson, 2012) dado um conjunto de frames anteriores da cena como entrada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTBZ_0njgKFt"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itTZSDW7sERy"
      },
      "source": [
        "### Modelo generativo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44XH8qbHiuFw",
        "outputId": "f90ca867-b077-41b8-d6b9-8cc94e30ee27"
      },
      "source": [
        "latent_dim = 32\n",
        "height = 32\n",
        "width = 32\n",
        "channels = 3\n",
        "\n",
        "generator_input = keras.Input(shape=(latent_dim,))\n",
        "\n",
        "# Resize das imagens de entrada para 16x16 com 128 canais/features\n",
        "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((16, 16, 128))(x)\n",
        "\n",
        "# Camada convolucional\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "# Camada convolucional para sobreamostragem das imagens de entrada para 32x32\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "# Camadas convolucionais adicionais\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "# Transformando para imagem 32x32 com um canal único\n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32)]              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32768)             1081344   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 16, 16, 256)       819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 32, 32, 256)       1048832   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 3)         37635     \n",
            "=================================================================\n",
            "Total params: 6,264,579\n",
            "Trainable params: 6,264,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvhDHCEUsH3J"
      },
      "source": [
        "### Modelo discriminante"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67JLfPzhqHUD",
        "outputId": "f5fb42bd-f19e-4957-9dfb-069c90c64f67"
      },
      "source": [
        "discriminator_input = layers.Input(shape=(height, width, channels))\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "# Camada de dropout\n",
        "x = layers.Dropout(0.4)(x)\n",
        "\n",
        "# Camada de classificação\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "discriminator = keras.models.Model(discriminator_input, x)\n",
        "discriminator.summary()\n",
        "\n",
        "# Otimizador do treinamento da rede com taxa de aprendizagem (lr)\n",
        "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
        "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 2, 2, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 790,913\n",
            "Trainable params: 790,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha_LfYqZsgRv"
      },
      "source": [
        "### Adversarial network\n",
        "\n",
        "Aqui, o modelo discriminante é posto em ação, sendo utlizado para discriminar as imagens entre reais e falsas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmDzx9mBsQb-"
      },
      "source": [
        "# Não treinar pesos do modelo discriminante\n",
        "discriminator.trainable = False\n",
        "\n",
        "gan_input = keras.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = keras.models.Model(gan_input, gan_output)\n",
        "\n",
        "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeEESI9VstG4"
      },
      "source": [
        "### Carregamento dos dados e treinamento da rede\n",
        "\n",
        "Para cada iteração do treino:\n",
        "* Gerar ruído aleatório - dados aleatórios para inicialização de vetores.\n",
        "* Gerar imagens com o modelo gerador com esses dados aleatórios.\n",
        "* Combinar as imagens geradas com as imagens reais.\n",
        "* Treinar o discriminante com essas imagens combinadas, separando entre reais e falsas\n",
        "* Gerar novos vetores aleatórios\n",
        "* Treinar rede GAN utilizando apenas esses últimos vetores aleatórios, com rótulos \"reais\" em todos em eles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V2w-x45jJJG"
      },
      "source": [
        "import os\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "xrPL2kr9SzZM",
        "outputId": "07b6949c-c734-4345-b436-556a67d54b62"
      },
      "source": [
        "# Carregando os dados\n",
        "filepath = glob('drive/MyDrive/Colab Notebooks/train/*.jpg')\n",
        "x_train = np.array([np.array(Image.open(x)) for x in filepath])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9c897cdcdd87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Carregando os dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/Colab Notebooks/train/*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-9c897cdcdd87>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Carregando os dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/Colab Notebooks/train/*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2850\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2852\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "0HWFNK5uX-Wf",
        "outputId": "9a7f2789-c480-4936-fee5-9900e4739a9e"
      },
      "source": [
        "# Normalizando os dados\n",
        "x_train = x_train.astype('float32') / 255."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-52907e77ca26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Normalizando os dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRa_7rXQjQFc"
      },
      "source": [
        "iterations = 500\n",
        "batch_size = 20\n",
        "save_dir = '/'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "7zr0c8FwssXa",
        "outputId": "694d6bdd-d737-4f9c-fa0e-31360498dcce"
      },
      "source": [
        "start = 0\n",
        "for step in range(iterations):\n",
        "    # Setando vetores alelatórios\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "\n",
        "    # Predição de imagens falsas\n",
        "    generated_images = generator.predict(random_latent_vectors)\n",
        "\n",
        "    # Combinando com imagens reais\n",
        "    stop = start + batch_size\n",
        "    real_images = x_train[start: stop]\n",
        "    combined_images = np.concatenate([generated_images, real_images])\n",
        "\n",
        "    # Rotulando dados entre reais e falsos\n",
        "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
        "                             np.zeros((batch_size, 1))])\n",
        "    # Adicionando ruído aleatório\n",
        "    labels += 0.05 * np.random.random(labels.shape)\n",
        "\n",
        "    # Treinando o otimizador\n",
        "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "\n",
        "    # Setando vetores alelatórios\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "\n",
        "    misleading_targets = np.zeros((batch_size, 1))\n",
        "\n",
        "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "    \n",
        "    start += batch_size\n",
        "    if start > len(x_train) - batch_size:\n",
        "      start = 0\n",
        "\n",
        "    # Salvando pesos e imagens geradas a cada 10 iterações\n",
        "    if step % 10 == 0:\n",
        "        gan.save_weights('gan.h5')\n",
        "\n",
        "        print('discriminator loss at step %s: %s' % (step, d_loss))\n",
        "        print('adversarial loss at step %s: %s' % (step, a_loss))\n",
        "\n",
        "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "        img.save(os.path.join(save_dir, 'generated_frog' + str(step) + '.png'))\n",
        "\n",
        "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "        img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "discriminator loss at step 0: 0.6879838705062866\n",
            "adversarial loss at step 0: 0.748475193977356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-55638c4fc0ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'generated_frog'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2129\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2131\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'content/generated_frog0.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTCpvQVkskVO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d42e409a-d4c8-4171-d560-c13e1bad6bf9"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iP7PbHTLCOtU",
        "outputId": "eed13a72-9a9f-4ce8-bd0c-2bdde155d2fb"
      },
      "source": [
        "os.path.join(save_dir, 'generated_frog' + str(step) + '.png')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/generated_frog0.png'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXr8ZZZOCXHs"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mrdEx7JQ0Ab"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}